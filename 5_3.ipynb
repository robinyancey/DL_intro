{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d3f7252"
      },
      "source": [
        "# Using a Pre-trained Convnet\n",
        "\n",
        "This notebook provides lecture notes on leveraging pre-trained convolutional neural networks (convnets) for image classification tasks. Using pre-trained models is a powerful technique that can significantly reduce training time and improve performance, especially when working with limited datasets.\n",
        "\n",
        "We will cover two main approaches:\n",
        "\n",
        "1.  **Feature Extraction:** Using the pre-trained network as a fixed feature extractor.\n",
        "2.  **Fine-tuning:** Unfreezing some of the layers of the pre-trained network and jointly training them with a new classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1d13c6"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "Feature extraction involves using the convolutional base of a pre-trained network to extract meaningful features from new images. These features are then fed into a new, smaller classifier (typically a few dense layers) that is trained on the new dataset.\n",
        "\n",
        "The idea is that the pre-trained convnet has already learned a hierarchy of features from a large dataset (like ImageNet), and these features are general enough to be useful for various image recognition tasks.\n",
        "\n",
        "Mathematically, if we have an input image $x$ and a pre-trained convnet $f$, feature extraction can be seen as applying the convolutional base $f_{conv}$ to $x$ to get a feature map $F(x) = f_{conv}(x)$. This feature map is then flattened and passed through a new classifier $g$: $\\hat{y} = g(\\text{flatten}(F(x)))$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4de818d",
        "outputId": "930b5d6f-c3d2-49df-f329-20c71a1a49c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Extracting features...\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 555ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 548ms/step\n",
            "Features extracted.\n",
            "Training classifier...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.7121 - val_accuracy: 0.9306 - val_loss: 0.2185\n",
            "Epoch 2/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1840 - val_accuracy: 0.9488 - val_loss: 0.1601\n",
            "Epoch 3/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1459 - val_accuracy: 0.9596 - val_loss: 0.1294\n",
            "Epoch 4/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1301 - val_accuracy: 0.9631 - val_loss: 0.1196\n",
            "Epoch 5/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1135 - val_accuracy: 0.9566 - val_loss: 0.1301\n",
            "Epoch 6/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1101 - val_accuracy: 0.9616 - val_loss: 0.1202\n",
            "Epoch 7/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1044 - val_accuracy: 0.9573 - val_loss: 0.1334\n",
            "Epoch 8/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0973 - val_accuracy: 0.9610 - val_loss: 0.1224\n",
            "Epoch 9/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0916 - val_accuracy: 0.9660 - val_loss: 0.1087\n",
            "Epoch 10/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0859 - val_accuracy: 0.9635 - val_loss: 0.1109\n",
            "Classifier trained.\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1169\n",
            "Test Loss: 0.1109\n",
            "Test Accuracy: 0.9635\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load a sample dataset (e.g., MNIST from scikit-learn)\n",
        "# MNIST is not ideal for showcasing ConvNets on images, but it's readily available\n",
        "# For better results, you would typically use a dataset like CIFAR-10 or your own image data\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Preprocess the data\n",
        "X = X.values.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet\n",
        "# We don't include the top classification layer\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(48, 48, 3)) # VGG16 expects 48x48 or larger images, and 3 channels\n",
        "\n",
        "# Since MNIST is 28x28 and grayscale, we need to resize and convert to 3 channels\n",
        "# This is a workaround for demonstration purposes. For real tasks, use appropriate datasets.\n",
        "X_train_resized = np.repeat(np.array([np.pad(img.squeeze(), ((10,10),(10,10)), 'constant') for img in X_train]).reshape(-1, 48, 48, 1), 3, axis=-1)\n",
        "X_test_resized = np.repeat(np.array([np.pad(img.squeeze(), ((10,10),(10,10)), 'constant') for img in X_test]).reshape(-1, 48, 48, 1), 3, axis=-1)\n",
        "\n",
        "\n",
        "# Extract features\n",
        "# This can be computationally expensive for large datasets\n",
        "print(\"Extracting features...\")\n",
        "train_features = conv_base.predict(X_train_resized)\n",
        "test_features = conv_base.predict(X_test_resized)\n",
        "print(\"Features extracted.\")\n",
        "\n",
        "# Flatten the extracted features\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "test_features = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "# Build a new classifier model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=train_features.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Training classifier...\")\n",
        "history = model.fit(train_features, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(test_features, y_test))\n",
        "print(\"Classifier trained.\")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_features, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80829398"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Fine-tuning is a more advanced technique where we not only add a new classifier on top of the pre-trained convolutional base but also unfreeze some of the layers in the convolutional base and train the entire model end-to-end on the new data.\n",
        "\n",
        "This allows the pre-trained model to adapt its learned features to the specific characteristics of the new dataset. It's crucial to unfreeze only the top layers of the convolutional base, as the lower layers have learned more general features, while the higher layers have learned more specific features.\n",
        "\n",
        "The process typically involves:\n",
        "\n",
        "1.  Adding a custom classifier on top of the pre-trained convolutional base.\n",
        "2.  Freezing the convolutional base.\n",
        "3.  Training the custom classifier.\n",
        "4.  Unfreezing some layers of the convolutional base.\n",
        "5.  Jointly training the unfrozen layers and the custom classifier with a very low learning rate.\n",
        "\n",
        "Mathematically, we are now training the parameters of both the unfrozen part of $f_{conv}$ (let's call it $f'_{conv}$) and the new classifier $g$. The combined model is $h(x) = g(\\text{flatten}(f'_{conv}(x)))$, and we optimize the parameters of $f'_{conv}$ and $g$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ddcc21",
        "outputId": "88a4c1c2-bf5d-4e87-9d5c-c069cbac0ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training top layers...\n",
            "Epoch 1/5\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1307s\u001b[0m 747ms/step - accuracy: 0.7868 - loss: 0.7057 - val_accuracy: 0.9409 - val_loss: 0.1943\n",
            "Epoch 2/5\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1418s\u001b[0m 811ms/step - accuracy: 0.9414 - loss: 0.1862 - val_accuracy: 0.9540 - val_loss: 0.1511\n",
            "Epoch 3/5\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1272s\u001b[0m 727ms/step - accuracy: 0.9539 - loss: 0.1481 - val_accuracy: 0.9592 - val_loss: 0.1328\n",
            "Epoch 4/5\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1246s\u001b[0m 712ms/step - accuracy: 0.9576 - loss: 0.1299 - val_accuracy: 0.9586 - val_loss: 0.1303\n",
            "Epoch 5/5\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1334s\u001b[0m 742ms/step - accuracy: 0.9631 - loss: 0.1202 - val_accuracy: 0.9630 - val_loss: 0.1175\n",
            "Top layers trained.\n",
            "Fine-tuning...\n",
            "Epoch 1/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2017s\u001b[0m 1s/step - accuracy: 0.9604 - loss: 0.1247 - val_accuracy: 0.9751 - val_loss: 0.0848\n",
            "Epoch 2/10\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2208s\u001b[0m 1s/step - accuracy: 0.9797 - loss: 0.0623 - val_accuracy: 0.9804 - val_loss: 0.0635\n",
            "Epoch 3/10\n",
            "\u001b[1m1709/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9838 - loss: 0.0502"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data (same as feature extraction example)\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "X = X.values.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y = to_categorical(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Resize and convert to 3 channels (same as feature extraction example)\n",
        "X_train_resized = np.repeat(np.array([np.pad(img.squeeze(), ((10,10),(10,10)), 'constant') for img in X_train]).reshape(-1, 48, 48, 1), 3, axis=-1)\n",
        "X_test_resized = np.repeat(np.array([np.pad(img.squeeze(), ((10,10),(10,10)), 'constant') for img in X_test]).reshape(-1, 48, 48, 1), 3, axis=-1)\n",
        "\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(48, 48, 3))\n",
        "\n",
        "# Add a custom classifier on top\n",
        "x = conv_base.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(y_train.shape[1], activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=conv_base.input, outputs=predictions)\n",
        "\n",
        "# Freeze the convolutional base\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile and train the classifier (Stage 1: Train only the top layers)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Training top layers...\")\n",
        "model.fit(X_train_resized, y_train,\n",
        "          epochs=5, # Train for fewer epochs in this stage\n",
        "          batch_size=32,\n",
        "          validation_data=(X_test_resized, y_test))\n",
        "print(\"Top layers trained.\")\n",
        "\n",
        "# Unfreeze some layers of the convolutional base (Stage 2: Fine-tuning)\n",
        "# Decide how many layers to unfreeze. Unfreezing the last few blocks is common.\n",
        "# You need to inspect the model summary to identify layer names/indices.\n",
        "# For VGG16, block5_conv1, block5_conv2, block5_conv3 are in the last block.\n",
        "for layer in conv_base.layers[15:]: # Unfreeze from a certain layer onwards (e.g., layer 15)\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), # Use a very low learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Fine-tuning...\")\n",
        "history_fine_tune = model.fit(X_train_resized, y_train,\n",
        "                              epochs=10, # Train for more epochs in this stage\n",
        "                              batch_size=32,\n",
        "                              validation_data=(X_test_resized, y_test))\n",
        "print(\"Fine-tuning complete.\")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_resized, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4058acc"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Using pre-trained convnets through feature extraction or fine-tuning are effective strategies for image classification, especially with limited data. Feature extraction is simpler and faster, while fine-tuning can potentially yield better performance by adapting the pre-trained features to the new dataset. The choice between the two depends on the size of your dataset and the similarity between the original task the model was trained on and your new task.\n",
        "\n",
        "Remember to experiment with different pre-trained models, the number of layers to unfreeze during fine-tuning, and hyperparameters to achieve the best results for your specific problem."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}