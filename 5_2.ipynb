{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5d3c3382"},"source":["# Training a Convnet from Scratch on a Small Dataset\n","\n","This notebook provides lecture notes on training a convolutional neural network (ConvNet) from scratch when you have a limited amount of data.\n","\n","## The relevance of deep learning for small-data problems\n","\n","Deep learning models, especially ConvNets, have achieved remarkable success in image classification tasks. While they typically require large datasets for optimal performance, they can still be effective on smaller datasets through techniques like data augmentation and transfer learning (which we won't cover in detail here).\n","\n","Even with small datasets, deep learning can often outperform traditional machine learning methods on complex image tasks by automatically learning hierarchical features directly from the data.\n","\n","## Downloading the data\n","\n","For this lecture, we will use a small image dataset available in scikit-learn."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"id":"295e4228","outputId":"dfd3da2d-ce7e-4aa5-e0ae-4c2297529aa7"},"source":["from sklearn.datasets import load_digits\n","import matplotlib.pyplot as plt\n","\n","# Load the digits dataset\n","digits = load_digits()\n","\n","# Display some sample images\n","fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 5))\n","for i, ax in enumerate(axes.flatten()):\n","    ax.imshow(digits.images[i], cmap='gray')\n","    ax.set_title(f'Digit: {digits.target[i]}')\n","    ax.axis('off')\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"Number of samples: {len(digits.images)}\")\n","print(f\"Image shape: {digits.images[0].shape}\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 10 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of samples: 1797\n","Image shape: (8, 8)\n"]}]},{"cell_type":"markdown","source":["## Building your network\n","\n","We will build a simple ConvNet model using Keras.\n","\n","- **Convolutional Layers:** These layers apply filters to the input image to detect features like edges, corners, and textures.  \n","The output of a convolutional layer is a feature map.\n","\n","  Mathematically, a convolution operation can be represented as:\n","\n","<center>\n","\n","$(I * K)(i, j) = \\sum_m \\sum_n I(i - m, j - n) K(m, n)$\n","\n","</center>\n","\n","   where *I* is the input image, *K* is the convolution kernel (filter), and *(i, j)* are the coordinates in the output feature map.\n","\n","\n","\n","- **Pooling Layers:** These layers reduce the spatial dimensions (width and height) of the feature maps, which helps reduce the number of parameters and computational cost, and makes the network more robust to small shifts in the input.  \n","Max pooling is a common type, where the maximum value within a window is taken.\n","\n","\n","- **Activation Functions:** Non-linear functions (like ReLU) are applied after convolutional layers to introduce non-linearity into the model, allowing it to learn more complex patterns.  \n","\n","     ReLU function:  $f(x) = \\max(0, x)$\n","\n","\n","\n","- **Flatten Layer:** This layer flattens the 2D feature maps into a 1D vector.\n","\n","- **Dense Layers:** These are fully connected layers that perform classification based on the features extracted by the convolutional and pooling layers.\n"],"metadata":{"id":"4UTPI4ADySpR"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"id":"166c4aea","outputId":"597ec517-7239-49fb-9ed8-863792232a0e"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Define the model\n","model = keras.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(10, activation='softmax') # 10 classes for digits 0-9\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,466\u001b[0m (76.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,466</span> (76.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,466\u001b[0m (76.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,466</span> (76.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"2c14b75e"},"source":["## Data preprocessing\n","\n","Before training, we need to preprocess the data:\n","\n","*   **Reshaping:** ConvNets expect input in the shape of (height, width, channels). Our images are 8x8, and since they are grayscale, they have 1 channel.\n","*   **Normalization:** Pixel values are typically scaled to a range between 0 and 1."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"819541cd","outputId":"100fd47e-b7ae-451b-ff83-a6b53cbbea9e"},"source":["import numpy as np\n","\n","# Reshape images to include the channel dimension\n","X = digits.images.reshape(-1, 8, 8, 1)\n","y = digits.target\n","\n","# Normalize pixel values\n","X = X.astype('float32') / 15.0 # Max pixel value is 15\n","\n","# Split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"Training data shape: {X_train.shape}\")\n","print(f\"Testing data shape: {X_test.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape: (1437, 8, 8, 1)\n","Testing data shape: (360, 8, 8, 1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"1b3f7178"},"source":["## Using data augmentation\n","\n","Data augmentation is a crucial technique for training deep learning models on small datasets. It involves creating new training examples by applying random transformations to the existing images, such as:\n","\n","*   Rotation\n","*   Zooming\n","*   Shifting\n","*   Flipping\n","\n","This helps to increase the size and diversity of the training data, making the model more robust and less prone to overfitting."]},{"cell_type":"code","metadata":{"id":"6f72e60d"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create a data augmentation generator\n","datagen = ImageDataGenerator(\n","    rotation_range=10,  # randomly rotate images by up to 10 degrees\n","    zoom_range=0.1,     # randomly zoom images by up to 10%\n","    width_shift_range=0.1, # randomly shift images horizontally by up to 10%\n","    height_shift_range=0.1 # randomly shift images vertically by up to 10%\n",")\n","\n","# Fit the generator on the training data\n","datagen.fit(X_train)\n","\n","# Now you can use the generator during training\n","# model.fit(datagen.flow(X_train, y_train, batch_size=32), ...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97ecec3e"},"source":["## Conclusion\n","\n","In this notebook, we explored how to train a ConvNet from scratch on a small dataset. We used the scikit-learn digits dataset, which is a good example of a small image dataset. We built a simple ConvNet model using Keras, preprocessed the data by reshaping and normalizing it, and used data augmentation to increase the size and diversity of the training data. These techniques are essential for achieving good performance when training deep learning models on limited data."]}]}